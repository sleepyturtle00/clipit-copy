# clipit 

Yet Another VQGAN-CLIP Codebase

![Alt text](https://user-images.githubusercontent.com/945979/127161241-71c12972-498c-48c3-bff7-df4d86306c3e.png "it looks like you're writing an image")

This started as a fork of @nerdyrodent's VQGAN-CLIP code which was based on the notebooks of @RiversWithWings and @advadnoun. But it quickly morphed into a version of the code that had been tuned up with slightly different behavior and features. It also runs either at the command line *or* in a notebook *or* (soon) in batch mode. 

Basically this is a verison of the notebook with opinionated defaults and slighly different internals. You are welcome to use it if you'd like.

For now, checkout [THE DEMO NOTEBOOKS](demos/README.md) - especially the super simple "Start Here" colab.


# Citations

```bibtex
@misc{unpublished2021clip,
    title  = {CLIP: Connecting Text and Images},
    author = {Alec Radford, Ilya Sutskever, Jong Wook Kim, Gretchen Krueger, Sandhini Agarwal},
    year   = {2021}
}
```
```bibtex
@misc{esser2020taming,
      title={Taming Transformers for High-Resolution Image Synthesis}, 
      author={Patrick Esser and Robin Rombach and Bj√∂rn Ommer},
      year={2020},
      eprint={2012.09841},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```
Katherine Crowson - https://github.com/crowsonkb
Adverb https://twitter.com/advadnoun

