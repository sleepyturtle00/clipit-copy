{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VQGAN+CLIP (with overlays).ipynb\"",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dribnet/clipit/blob/master/demos/Moar_Settings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CppIQlPhhwhs"
      },
      "source": [
        "# Generate images from text prompts with VQGAN and CLIP (z+quantize method).\n",
        "\n",
        "Originally made by Katherine Crowson (https://github.com/crowsonkb, https://twitter.com/RiversHaveWings). The original BigGAN+CLIP method was by https://twitter.com/advadnoun.\n",
        " Added some explanations and modifications by Eleiber#8347, pooling trick by Crimeacs#8222 (https://twitter.com/EarthML1) and the GUI was made with the help of Abulafia#3734.\n",
        "\n",
        " This notebook supports [@dribnet's clipit repo](https://github.com/dribnet/clipit) which is a fork of nerdyrodent's command line version with some features such as overlay added.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-nnPDoDFCp6n"
      },
      "source": [
        "# @title Licensed under the MIT License\n",
        "\n",
        "# Copyright (c) 2021 Katherine Crowson\n",
        "\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "# of this software and associated documentation files (the \"Software\"), to deal\n",
        "# in the Software without restriction, including without limitation the rights\n",
        "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "# copies of the Software, and to permit persons to whom the Software is\n",
        "# furnished to do so, subject to the following conditions:\n",
        "\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
        "# THE SOFTWARE.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkUfzT60ZZ9q"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA1PHoJrRiK9"
      },
      "source": [
        "!git clone https://github.com/openai/CLIP\n",
        "# !pip install taming-transformers\n",
        "!git clone https://github.com/CompVis/taming-transformers.git\n",
        "!rm -Rf clipit\n",
        "!git clone https://github.com/dribnet/clipit\n",
        "!pip install ftfy regex tqdm omegaconf pytorch-lightning\n",
        "!pip install kornia\n",
        "!pip install imageio-ffmpeg   \n",
        "!pip install einops\n",
        "!pip install torch-optimizer\n",
        "!pip install easydict\n",
        "!pip install braceexpand\n",
        "!pip install git+https://github.com/pvigier/perlin-numpy\n",
        "!mkdir steps\n",
        "!wget https://user-images.githubusercontent.com/945979/126260797-adc60317-9518-40de-8700-b1f93e81e0ec.png -O this_is_fine.png\n",
        "!wget https://user-images.githubusercontent.com/945979/126415385-d70ff2b0-f021-4238-9621-6180d33b242c.jpg -O perfume.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTg77tNuF7Og"
      },
      "source": [
        "By default, the notebook downloads the 1024 and 16384 models from ImageNet. There are others like COCO-Stuff, WikiArt or S-FLCKR, which are heavy, and if you are not going to use them it would be useless to download them, so if you want to use them, simply remove the numerals at the beginning of the lines depending on the model you want (the model name is at the end of the lines)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhhdWrSxQhwg",
        "cellView": "form"
      },
      "source": [
        "#@title Selection of models to download\n",
        "#@markdown By default, the notebook downloads the 1024 and 16384 models from ImageNet. There are others like COCO-Stuff, WikiArt 1024, WikiArt 16384, FacesHQ or S-FLCKR, which are heavy, and if you are not going to use them it would be pointless to download them, so if you want to use them, simply select the models to download.\n",
        "\n",
        "imagenet_1024 = False #@param {type:\"boolean\"}\n",
        "imagenet_16384 = True #@param {type:\"boolean\"}\n",
        "coco = False #@param {type:\"boolean\"}\n",
        "faceshq = False #@param {type:\"boolean\"}\n",
        "wikiart_1024 = False #@param {type:\"boolean\"}\n",
        "wikiart_16384 = False #@param {type:\"boolean\"}\n",
        "sflckr = False #@param {type:\"boolean\"}\n",
        "openimages_8192 = False #@param {type:\"boolean\"}\n",
        "\n",
        "if imagenet_1024:\n",
        "  !curl -L -o vqgan_imagenet_f16_1024.yaml -C - 'http://mirror.io.community/blob/vqgan/vqgan_imagenet_f16_1024.yaml' #ImageNet 1024\n",
        "  !curl -L -o vqgan_imagenet_f16_1024.ckpt -C - 'http://mirror.io.community/blob/vqgan/vqgan_imagenet_f16_1024.ckpt'  #ImageNet 1024\n",
        "if imagenet_16384:\n",
        "  !curl -L -o vqgan_imagenet_f16_16384.yaml -C - 'http://mirror.io.community/blob/vqgan/vqgan_imagenet_f16_16384.yaml' #ImageNet 16384\n",
        "  !curl -L -o vqgan_imagenet_f16_16384.ckpt -C - 'http://mirror.io.community/blob/vqgan/vqgan_imagenet_f16_16384.ckpt' #ImageNet 16384\n",
        "if openimages_8192:\n",
        "  !curl -L -o vqgan_openimages_f16_8192.yaml -C - 'https://heibox.uni-heidelberg.de/d/2e5662443a6b4307b470/files/?p=%2Fconfigs%2Fmodel.yaml&dl=1' #ImageNet 16384\n",
        "  !curl -L -o vqgan_openimages_f16_8192.ckpt -C - 'https://heibox.uni-heidelberg.de/d/2e5662443a6b4307b470/files/?p=%2Fckpts%2Flast.ckpt&dl=1' #ImageNet 16384\n",
        "\n",
        "if coco:\n",
        "  !curl -L -o coco.yaml -C - 'https://dl.nmkd.de/ai/clip/coco/coco.yaml' #COCO\n",
        "  !curl -L -o coco.ckpt -C - 'https://dl.nmkd.de/ai/clip/coco/coco.ckpt' #COCO\n",
        "if faceshq:\n",
        "  !curl -L -o faceshq.yaml -C - 'https://drive.google.com/uc?export=download&id=1fHwGx_hnBtC8nsq7hesJvs-Klv-P0gzT' #FacesHQ\n",
        "  !curl -L -o faceshq.ckpt -C - 'https://app.koofr.net/content/links/a04deec9-0c59-4673-8b37-3d696fe63a5d/files/get/last.ckpt?path=%2F2020-11-13T21-41-45_faceshq_transformer%2Fcheckpoints%2Flast.ckpt' #FacesHQ\n",
        "if wikiart_1024: \n",
        "  !curl -L -o wikiart_1024.yaml -C - 'http://mirror.io.community/blob/vqgan/wikiart.yaml' #WikiArt 1024\n",
        "  !curl -L -o wikiart_1024.ckpt -C - 'http://mirror.io.community/blob/vqgan/wikiart.ckpt' #WikiArt 1024\n",
        "if wikiart_16384: \n",
        "  !curl -L -o wikiart_16384.yaml -C - 'http://mirror.io.community/blob/vqgan/wikiart_16384.yaml' #WikiArt 16384\n",
        "  !curl -L -o wikiart_16384.ckpt -C - 'http://mirror.io.community/blob/vqgan/wikiart_16384.ckpt' #WikiArt 16384\n",
        "if sflckr:\n",
        "  !curl -L -o sflckr.yaml -C - 'https://heibox.uni-heidelberg.de/d/73487ab6e5314cb5adba/files/?p=%2Fconfigs%2F2020-11-09T13-31-51-project.yaml&dl=1' #S-FLCKR\n",
        "  !curl -L -o sflckr.ckpt -C - 'https://heibox.uni-heidelberg.de/d/73487ab6e5314cb5adba/files/?p=%2Fcheckpoints%2Flast.ckpt&dl=1' #S-FLCKR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tthw0YaispD"
      },
      "source": [
        "## Settings for this run:\n",
        "Mainly what you will have to modify will be `texts:`, there you can place the text or texts you want to generate (separated with `|`). It is a list because you can put more than one text, and so the AI ​​tries to 'mix' the images, giving the same priority to both texts.\n",
        "\n",
        "To use an initial image to the model, you just have to upload a file to the Colab environment (in the section on the left), and then modify `init_image:` putting the exact name of the file. Example: `sample.png`\n",
        "\n",
        "You can also modify the model by changing the lines that say `model:`. Currently ImageNet 1024, ImageNet 16384, WikiArt 1024, WikiArt 16384, S-FLCKR and COCO-Stuff are available. To activate them you have to have downloaded them first, and then you can simply select it.\n",
        "\n",
        "You can also use `target_images`, which is basically putting one or more images on it that the AI ​​will take as a \"target\", fulfilling the same function as putting text on it. To put more than one you have to use `|` as a separator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdlpRFL8UAlW",
        "cellView": "form"
      },
      "source": [
        "#@title Parameters\n",
        "prompts = \"this is fine\" #@param {type:\"string\"}\n",
        "image_prompts = \"\" #@param {type:\"string\"}\n",
        "init_image = \"this_is_fine.png\" #@param {type:\"string\"}\n",
        "overlay_every = 20 #@param {type:\"number\"}\n",
        "model = \"vqgan_imagenet_f16_16384\" #@param [\"vqgan_imagenet_f16_16384\", \"vqgan_imagenet_f16_1024\", \"vqgan_openimages_f16_8192\", \"wikiart_1024\", \"wikiart_16384\", \"coco\", \"faceshq\", \"sflckr\"]\n",
        "seed = 42 #@param {type:\"number\"}\n",
        "display_freq =  50 #@param {type:\"number\"}\n",
        "max_iterations = 400 #@param {type:\"number\"}\n",
        "width =  256 #@param {type:\"number\"}\n",
        "height = 256 #@param {type:\"number\"}\n",
        "\n",
        "############# SETUP WITH THESE SETTINGS\n",
        "\n",
        "model_names={\"vqgan_imagenet_f16_16384\": 'ImageNet 16384',\"vqgan_imagenet_f16_1024\":\"ImageNet 1024\", 'vqgan_openimages_f16_8192':'OpenImages 8912',\n",
        "                 \"wikiart_1024\":\"WikiArt 1024\", \"wikiart_16384\":\"WikiArt 16384\", \"coco\":\"COCO-Stuff\", \"faceshq\":\"FacesHQ\", \"sflckr\":\"S-FLCKR\"}\n",
        "name_model = model_names[model]     \n",
        "\n",
        "if seed == -1:\n",
        "    seed = None\n",
        "if overlay_every == \"None\":\n",
        "    overlay_every = None\n",
        "if init_image == \"None\":\n",
        "    init_image = None\n",
        "if image_prompts == \"None\" or not image_prompts:\n",
        "    image_prompts = []\n",
        "\n",
        "# Simple setup\n",
        "from clipit import generate\n",
        "import easydict\n",
        "\n",
        "args = easydict.EasyDict({\n",
        "    \"prompts\": prompts,\n",
        "    \"image_prompts\": image_prompts,\n",
        "    \"init_image\": init_image,\n",
        "    \"overlay_every\": overlay_every,\n",
        "    \"vqgan_config\": f'{model}.yaml',\n",
        "    \"vqgan_checkpoint\": f'{model}.ckpt',\n",
        "    \"seed\": seed,\n",
        "    \"display_freq\": display_freq,\n",
        "    \"max_iterations\": max_iterations,\n",
        "    \"size\": [width, height],\n",
        "    \"init_noise\": \"pixels\"\n",
        "})\n",
        "\n",
        "vq_parser = generate.setup_parser()\n",
        "settings = generate.process_args(vq_parser, namespace=args)\n",
        "generate.do_init(settings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmCtyfJD3DRW"
      },
      "source": [
        "\n",
        "from IPython import display\n",
        "generate.do_run(settings)\n",
        "if settings.overlay_every is not None:\n",
        "  print(\"Final version with overlay\")\n",
        "  display.display(display.Image(\"overlaid.png\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOjp_zwsoWUn"
      },
      "source": [
        "## Another run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x6UYID4Kdnb",
        "cellView": "form"
      },
      "source": [
        "#@title Parameters\n",
        "prompts = \"photo of perfume\" #@param {type:\"string\"}\n",
        "image_prompts = \"\" #@param {type:\"string\"}\n",
        "init_image = \"perfume.jpg\" #@param {type:\"string\"}\n",
        "init_image_alpha = 200 #@param {type:\"number\"}\n",
        "init_weight = 0.5 #@param {type:\"number\"}\n",
        "overlay_every =  0 #@param {type:\"number\"}\n",
        "model = \"vqgan_imagenet_f16_16384\" #@param [\"vqgan_imagenet_f16_16384\", \"vqgan_imagenet_f16_1024\", \"vqgan_openimages_f16_8192\", \"wikiart_1024\", \"wikiart_16384\", \"coco\", \"faceshq\", \"sflckr\"]\n",
        "seed = 42 #@param {type:\"number\"}\n",
        "display_freq =  50 #@param {type:\"number\"}\n",
        "max_iterations = 200 #@param {type:\"number\"}\n",
        "width =  256 #@param {type:\"number\"}\n",
        "height = 256 #@param {type:\"number\"}\n",
        "\n",
        "############# SETUP WITH THESE SETTINGS\n",
        "\n",
        "model_names={\"vqgan_imagenet_f16_16384\": 'ImageNet 16384',\"vqgan_imagenet_f16_1024\":\"ImageNet 1024\", 'vqgan_openimages_f16_8192':'OpenImages 8912',\n",
        "                 \"wikiart_1024\":\"WikiArt 1024\", \"wikiart_16384\":\"WikiArt 16384\", \"coco\":\"COCO-Stuff\", \"faceshq\":\"FacesHQ\", \"sflckr\":\"S-FLCKR\"}\n",
        "name_model = model_names[model]     \n",
        "\n",
        "if seed == -1:\n",
        "    seed = None\n",
        "if overlay_every == \"None\":\n",
        "    overlay_every = None\n",
        "if init_image == \"None\":\n",
        "    init_image = None\n",
        "if image_prompts == \"None\" or not image_prompts:\n",
        "    image_prompts = []\n",
        "\n",
        "# Simple setup\n",
        "from clipit import generate\n",
        "import easydict\n",
        "\n",
        "args = easydict.EasyDict({\n",
        "    \"prompts\": prompts,\n",
        "    \"image_prompts\": image_prompts,\n",
        "    \"init_image\": init_image,\n",
        "    \"init_image_alpha\": init_image_alpha,\n",
        "    \"init_weight\": init_weight,\n",
        "    \"overlay_every\": overlay_every,\n",
        "    \"vqgan_config\": f'{model}.yaml',\n",
        "    \"vqgan_checkpoint\": f'{model}.ckpt',\n",
        "    \"seed\": seed,\n",
        "    \"display_freq\": display_freq,\n",
        "    \"max_iterations\": max_iterations,\n",
        "    \"size\": [width, height],\n",
        "    \"init_noise\": \"pixels\"\n",
        "})\n",
        "\n",
        "vq_parser = generate.setup_parser()\n",
        "settings = generate.process_args(vq_parser, namespace=args)\n",
        "generate.do_init(settings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyOOFoNxqOt0"
      },
      "source": [
        "\n",
        "from IPython import display\n",
        "generate.do_run(settings)\n",
        "if settings.overlay_every is not None:\n",
        "  print(\"Final version with overlay\")\n",
        "  display.display(display.Image(\"overlaid.png\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}